{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b3bab0e-174e-43e9-8615-ebcb3826e71a",
   "metadata": {},
   "source": [
    " ### Работа с различными источниками данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b38fca02-e0a2-49dd-b32f-50152f811e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество строк: 10000\n",
      "Количество столбцов: 7\n",
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- hire_date: string (nullable = true)\n",
      " |-- is_active: boolean (nullable = true)\n",
      "\n",
      "+-------+------------------+---------+----------------+-----------------+----------+----------+\n",
      "|summary|                id|     name|             age|           salary|department| hire_date|\n",
      "+-------+------------------+---------+----------------+-----------------+----------+----------+\n",
      "|  count|             10000|    10000|           10000|            10000|     10000|     10000|\n",
      "|   mean|            5000.5|     NULL|         48.8047|       89558.4295|      NULL|      NULL|\n",
      "| stddev|2886.8956799071675|     NULL|18.2766124149454|34605.27441500447|      NULL|      NULL|\n",
      "|    min|                 1|   User_1|              18|            30000|   Finance|2020-11-07|\n",
      "|    max|             10000|User_9999|              80|           149988|     Sales|2025-11-06|\n",
      "+-------+------------------+---------+----------------+-----------------+----------+----------+\n",
      "\n",
      "+---+----+---+------+----------+---------+---------+\n",
      "| id|name|age|salary|department|hire_date|is_active|\n",
      "+---+----+---+------+----------+---------+---------+\n",
      "|  0|   0|  0|     0|         0|        0|        0|\n",
      "+---+----+---+------+----------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, BooleanType\n",
    "from pyspark.sql.functions import count, when, col\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Module_2_DataFrame_Basics\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", 4) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# 1. Прочитайте CSV файл с явной схемой\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"salary\", IntegerType(), True),\n",
    "    StructField(\"department\", StringType(), True),\n",
    "    StructField(\"hire_date\", StringType(), True),\n",
    "    StructField(\"is_active\", BooleanType(), True)\n",
    "])\n",
    "\n",
    "path_file = \"..//../data/employees.csv\"\n",
    "\n",
    "df = spark.read.csv(\n",
    "    path_file,\n",
    "    header=True,\n",
    "    schema=schema\n",
    ")\n",
    "\n",
    "# 2. Выведите информацию о DataFrame\n",
    "print(f\"Количество строк: {df.count()}\")\n",
    "print(f\"Количество столбцов: {len(df.columns)}\")\n",
    "df.printSchema()\n",
    "df.describe().show()\n",
    "\n",
    "# 3. Проверьте наличие NULL значений\n",
    "df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e434988-f8b9-40a6-b25a-dfdde161cef6",
   "metadata": {},
   "source": [
    "### Основные операции с DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88b6660f-de84-4451-b3be-cba7cd180d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+------+----------+\n",
      "|     name|age|salary|department|\n",
      "+---------+---+------+----------+\n",
      "|User_3787| 30|149988|     Sales|\n",
      "|User_6004| 37|149970|     Sales|\n",
      "|User_1446| 26|149967|   Finance|\n",
      "|User_3659| 52|149964|        HR|\n",
      "|User_6422| 34|149945|   Finance|\n",
      "|User_6161| 60|149909|   Finance|\n",
      "|User_7886| 30|149901|     Sales|\n",
      "|User_1407| 68|149885|        IT|\n",
      "|User_4109| 68|149882|        IT|\n",
      "|User_3945| 44|149869|        IT|\n",
      "+---------+---+------+----------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+----------+\n",
      "|department|\n",
      "+----------+\n",
      "|     Sales|\n",
      "|        HR|\n",
      "|        IT|\n",
      "|   Finance|\n",
      "| Marketing|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Выберите только нужные столбцы\n",
    "selected_df = df.select(\"name\", \"age\", \"salary\", \"department\")\n",
    "\n",
    "# 2. Отфильтруйте данные\n",
    "filtered_df = selected_df.filter((col(\"age\") > 25) & (col(\"salary\") > 50000))\n",
    "\n",
    "# 3. Отсортируйте по зарплате\n",
    "sorted_df = filtered_df.orderBy(col(\"salary\").desc())\n",
    "\n",
    "# 4. Покажите результат\n",
    "sorted_df.show(10)\n",
    "\n",
    "# 5. Найдите уникальные департаменты\n",
    "df.select(\"department\").distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd30c150-2893-4950-99cd-509cc955e75f",
   "metadata": {},
   "source": [
    "### Работа с NULL значениями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df3aca8d-ca5e-4037-a45d-7ac5bab4e48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+------+----------+----------+---------+-----+\n",
      "| id|   name|age|salary|department| hire_date|is_active|bonus|\n",
      "+---+-------+---+------+----------+----------+---------+-----+\n",
      "|  2| User_2| 76| 52377|        IT|2024-08-13|    false| NULL|\n",
      "|  3| User_3| 43| 50963|   Finance|2023-08-05|     true| NULL|\n",
      "|  6| User_6| 34| 33522|        HR|2024-12-08|     true| NULL|\n",
      "|  7| User_7| 73| 47237|        HR|2025-06-18|    false| NULL|\n",
      "|  8| User_8| 41| 40584|        HR|2023-09-15|    false| NULL|\n",
      "|  9| User_9| 42| 62464|   Finance|2021-09-29|    false| NULL|\n",
      "| 10|User_10| 18| 79601|   Finance|2023-06-07|    false| NULL|\n",
      "| 11|User_11| 79| 61546|     Sales|2025-08-31|     true| NULL|\n",
      "| 14|User_14| 27| 49382| Marketing|2022-10-31|     true| NULL|\n",
      "| 15|User_15| 56| 69706|   Finance|2023-12-17|     true| NULL|\n",
      "| 19|User_19| 74| 49461|        IT|2022-06-11|     true| NULL|\n",
      "| 20|User_20| 35| 42436|   Finance|2021-12-15|     true| NULL|\n",
      "| 24|User_24| 37| 63200|   Finance|2021-06-06|     true| NULL|\n",
      "| 26|User_26| 59| 32825|        IT|2023-03-17|     true| NULL|\n",
      "| 28|User_28| 29| 42472|        IT|2024-01-21|     true| NULL|\n",
      "| 29|User_29| 33| 77231|   Finance|2023-03-12|    false| NULL|\n",
      "| 30|User_30| 70| 76166|        IT|2021-10-05|     true| NULL|\n",
      "| 32|User_32| 36| 42065|   Finance|2025-04-05|    false| NULL|\n",
      "| 35|User_35| 22| 50388|     Sales|2025-03-09|     true| NULL|\n",
      "| 38|User_38| 53| 34296|        IT|2023-02-07|    false| NULL|\n",
      "+---+-------+---+------+----------+----------+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+---+-------+---+------+----------+----------+---------+------------------+\n",
      "| id|   name|age|salary|department| hire_date|is_active|             bonus|\n",
      "+---+-------+---+------+----------+----------+---------+------------------+\n",
      "|  1| User_1| 78|100957|        HR|2025-05-18|     true|           10095.7|\n",
      "|  2| User_2| 76| 52377|        IT|2024-08-13|    false|               0.0|\n",
      "|  3| User_3| 43| 50963|   Finance|2023-08-05|     true|               0.0|\n",
      "|  4| User_4| 50|110839|   Finance|2021-01-19|     true|11083.900000000001|\n",
      "|  5| User_5| 77|148058| Marketing|2023-10-11|    false|14805.800000000001|\n",
      "|  6| User_6| 34| 33522|        HR|2024-12-08|     true|               0.0|\n",
      "|  7| User_7| 73| 47237|        HR|2025-06-18|    false|               0.0|\n",
      "|  8| User_8| 41| 40584|        HR|2023-09-15|    false|               0.0|\n",
      "|  9| User_9| 42| 62464|   Finance|2021-09-29|    false|               0.0|\n",
      "| 10|User_10| 18| 79601|   Finance|2023-06-07|    false|               0.0|\n",
      "| 11|User_11| 79| 61546|     Sales|2025-08-31|     true|               0.0|\n",
      "| 12|User_12| 49|116684|        IT|2024-05-31|     true|11668.400000000001|\n",
      "| 13|User_13| 73|108522|        HR|2023-04-30|    false|           10852.2|\n",
      "| 14|User_14| 27| 49382| Marketing|2022-10-31|     true|               0.0|\n",
      "| 15|User_15| 56| 69706|   Finance|2023-12-17|     true|               0.0|\n",
      "| 16|User_16| 20| 81572|        IT|2025-09-07|     true| 8157.200000000001|\n",
      "| 17|User_17| 48|110119|        IT|2023-01-10|     true|11011.900000000001|\n",
      "| 18|User_18| 69|127853|        HR|2021-06-19|     true|12785.300000000001|\n",
      "| 19|User_19| 74| 49461|        IT|2022-06-11|     true|               0.0|\n",
      "| 20|User_20| 35| 42436|   Finance|2021-12-15|     true|               0.0|\n",
      "+---+-------+---+------+----------+----------+---------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Оригинальный размер: 10000\n",
      "После очистки: 10000\n"
     ]
    }
   ],
   "source": [
    "# Создайте DataFrame с NULL значениями для практики\n",
    "# Добавим искусственные NULL значения\n",
    "df_with_nulls = df.withColumn(\"bonus\", \n",
    "    when(col(\"salary\") > 80000, col(\"salary\") * 0.1)\n",
    "    .otherwise(None)\n",
    ")\n",
    "\n",
    "# Покажем строки с NULL в bonus\n",
    "df_with_nulls.filter(col(\"bonus\").isNull()).show()\n",
    "\n",
    "# Заполним NULL значениями\n",
    "df_filled = df_with_nulls.na.fill({\"bonus\": 0})\n",
    "df_filled.show()\n",
    "\n",
    "# Удалим строки с NULL в важных столбцах\n",
    "df_cleaned = df_with_nulls.na.drop(subset=[\"name\", \"age\"])\n",
    "print(f\"Оригинальный размер: {df_with_nulls.count()}\")\n",
    "print(f\"После очистки: {df_cleaned.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612dd2bf-efbe-46b2-ac22-2216811ebdcb",
   "metadata": {},
   "source": [
    "### Работа с различными форматами данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c464c37-6aaf-4e04-9f3a-7ae92960dbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV count time: 0.06s, Count: 10000\n",
      "Parquet count time: 0.14s, Count: 10000\n"
     ]
    }
   ],
   "source": [
    "# 1. Прочитайте CSV и преобразуйте в Parquet\n",
    "df_csv = spark.read.csv(\"../../data/employees_extended.csv\", header=True, inferSchema=True)\n",
    "df_csv.write.mode(\"overwrite\").parquet(\"../../data/employees.parquet\")\n",
    "\n",
    "# 2. Прочитайте Parquet и выполните операции\n",
    "df_parquet = spark.read.parquet(\"../../data/employees.parquet\")\n",
    "\n",
    "# 3. Проверьте производительность\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "csv_count = df_csv.count()\n",
    "csv_time = time.time() - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "parquet_count = df_parquet.count()\n",
    "parquet_time = time.time() - start_time\n",
    "\n",
    "print(f\"CSV count time: {csv_time:.2f}s, Count: {csv_count}\")\n",
    "print(f\"Parquet count time: {parquet_time:.2f}s, Count: {parquet_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7f2708-2dfd-4575-8c67-24b77600f4ae",
   "metadata": {},
   "source": [
    "### Продвинутая фильтрация и выбор столбцов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d11df288-1e4e-4a6c-a47b-467d9e078c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-----------------+------+-------------+------------------+\n",
      "|sale_id|   product|     total_amount|region|customer_tier|avg_price_per_unit|\n",
      "+-------+----------+-----------------+------+-------------+------------------+\n",
      "|      2|  Keyboard|8256.900000000001| South|      Premium| 825.6900000000002|\n",
      "|      3|   Monitor|          12304.8| North|      Premium|            1538.1|\n",
      "|      7|     Mouse|          15964.0| North|      Premium|            1596.4|\n",
      "|      8|  Keyboard|           3295.4| South|      Regular|            823.85|\n",
      "|     14|Headphones|7787.200000000001| North|      Premium|           1557.44|\n",
      "|     15|   Printer|           4836.0| North|      Regular|             806.0|\n",
      "|     20|     Phone|          5777.64| North|      Premium|           1925.88|\n",
      "|     25|   Printer|          1299.24| North|      Regular|            649.62|\n",
      "|     27|  Keyboard|         11883.78| North|      Premium|           1980.63|\n",
      "|     29|    Camera|9736.230000000001| South|      Premium|           1390.89|\n",
      "+-------+----------+-----------------+------+-------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when, expr, substring\n",
    "\n",
    "# Работа с данными продаж\n",
    "sales_df = spark.read.csv(\"../../data/sales_extended.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Сложная фильтрация\n",
    "high_value_sales = sales_df.filter(\n",
    "    (col(\"total_amount\") > 1000) & \n",
    "    (col(\"quantity\") >= 2) & \n",
    "    (col(\"region\").isin([\"North\", \"South\"]))\n",
    ")\n",
    "\n",
    "# Выбор и преобразование столбцов\n",
    "processed_df = high_value_sales.select(\n",
    "    col(\"sale_id\"),\n",
    "    col(\"product\"),\n",
    "    col(\"total_amount\"),\n",
    "    col(\"region\"),\n",
    "    # Создание нового столбца на основе условий\n",
    "    when(col(\"total_amount\") > 5000, \"Premium\").otherwise(\"Regular\").alias(\"customer_tier\"),\n",
    "    # Вычисление на основе других столбцов\n",
    "    (col(\"total_amount\") / col(\"quantity\")).alias(\"avg_price_per_unit\")\n",
    ")\n",
    "\n",
    "processed_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6a20e9-9e59-4ddb-b9fe-26b12a9d48eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
